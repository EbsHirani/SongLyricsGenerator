{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SongGenerator.ipynb",
      "provenance": [],
      "mount_file_id": "1BXYhdGJde1OxkTUk22RjCYCrAjKYTA3j",
      "authorship_tag": "ABX9TyPEJK1yImTcN1NgS2hwDLBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EbsHirani/SongLyricsGenerator/blob/master/SongGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwK5eISBi1_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/SongGenerator/datasets/mousehead/songlyrics\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23RvEj6jHuM",
        "colab_type": "code",
        "outputId": "9c49a4bd-56cb-4f06-9f55-ffdba70a4b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "songs = pd.read_csv(\"songdata.csv\")\n",
        "songs.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Ahe's My Kind Of Girl</td>\n",
              "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
              "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Andante, Andante</td>\n",
              "      <td>/a/abba/andante+andante_20002708.html</td>\n",
              "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>As Good As New</td>\n",
              "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
              "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang</td>\n",
              "      <td>/a/abba/bang_20598415.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang-A-Boomerang</td>\n",
              "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist  ...                                               text\n",
              "0   ABBA  ...  Look at her face, it's a wonderful face  \\nAnd...\n",
              "1   ABBA  ...  Take it easy with me, please  \\nTouch me gentl...\n",
              "2   ABBA  ...  I'll never know why I had to go  \\nWhy I had t...\n",
              "3   ABBA  ...  Making somebody happy is a question of give an...\n",
              "4   ABBA  ...  Making somebody happy is a question of give an...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEb_iAPijgOI",
        "colab_type": "code",
        "outputId": "cffd5a2e-3d84-47fc-9e6a-16d3502fbf32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "sentences = songs[\"text\"].str.cat(sep='\\n').lower().split(\"\\n\")\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqRzJQAeq3C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = {id : word for word, id in tokenizer.word_index.items()}\n",
        "wordx = {word : id for word, id in tokenizer.word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnZ9t1ZGr0e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx[len(tokenizer.word_index)+1] = \"<EOF>\"\n",
        "wordx[\"<EOF>\"] = len(tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9fwrdeMsbEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx[0] = \"<PAD>\"\n",
        "wordx[\"<PAD>\"] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft0FzbHsw7hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR6vWNRwlBER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "def get_output(input):\n",
        "  temp = input.copy()\n",
        "  temp.append(wordx[\"<EOF>\"])\n",
        "  return temp[1:]\n",
        "def generator(sentences, batch_size = 64):\n",
        "  while True:\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "      if i+batch_size < len(sentences):\n",
        "        curr_batch = sentences[i:i+batch_size]\n",
        "        input_sequences = tokenizer.texts_to_sequences(curr_batch)\n",
        "        output_sequences = list(map(get_output, input_sequences))\n",
        "        input_sequences = pad_sequences(input_sequences, padding=\"post\")\n",
        "        output_sequences = pad_sequences(output_sequences, padding = \"post\")\n",
        "\n",
        "        yield input_sequences, to_categorical(output_sequences, num_classes = vocab_len)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjhYpitPxfo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Lambda, Flatten, LSTM, Input, Embedding\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import  backend as K\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization , MaxPooling2D, Activation\n",
        "\n",
        "inputs = Input(shape=(None,))\n",
        "emb = Embedding(vocab_len, 64)\n",
        "emb_out = emb(inputs)\n",
        "lstm = LSTM(64, return_sequences = True, return_state = True)\n",
        "lstm_out, _, _ = lstm(emb_out)\n",
        "soft = Dense(vocab_len, activation = \"softmax\")\n",
        "out = soft(lstm_out)\n",
        "model = Model(inputs, out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwYh3hC11x2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "LR = 1e-2\n",
        "model.compile(optimizer = Adam(LR), loss = categorical_crossentropy, metrics = [\"accuracy\"])\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjuHfLFn40us",
        "colab_type": "code",
        "outputId": "91511d1b-80cd-421a-c977-f3acdeb8a758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_gen = generator(sentences[:int(len(sentences)*0.9)], BATCH_SIZE)\n",
        "val_gen = generator(sentences[int(len(sentences)*0.9):], BATCH_SIZE)\n",
        "history = model.fit_generator(train_gen, steps_per_epoch= 500, validation_data = val_gen, validation_steps= 50, epochs = 200, callbacks = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50), ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)])\n",
        "#setting steps per epoch lower than the actual number so that the model gets saved frequently on progress.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            " 55/500 [==>...........................] - ETA: 3:07 - loss: 2.1347 - accuracy: 0.6607"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq9fO12J8V-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_h_in = Input(shape = (64,))\n",
        "state_c_in  = Input(shape = (64,))\n",
        "state_in = [state_h_in,state_c_in]\n",
        "emb_out_pred = emb(inputs) \n",
        "out_pred, state_h_out, state_c_out = lstm(emb_out_pred, initial_state = state_in)\n",
        "out_pred = soft(out_pred)\n",
        "model_second = Model([inputs] + state_in, [out_pred, state_h_out, state_c_out])\n",
        "\n",
        "# emb_out_pred2 = emb(inputs) \n",
        "# out_pred2, state_h_out2, state_c_out2 = lstm(emb_out_pred2)\n",
        "# out_pred2 = soft(out_pred2)\n",
        "# model_init = Model(inputs , [out_pred, state_h_out, state_c_out])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyX3_G7iRCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_out_pred2 = emb(inputs) \n",
        "out_pred2, state_h_out2, state_c_out2 = lstm(emb_out_pred2)\n",
        "out_pred2 = soft(out_pred2)\n",
        "model_init = Model(inputs , [out_pred2, state_h_out2, state_c_out2])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyTivonZ7dcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 10\n",
        "def predict(word):\n",
        "  \n",
        "  word = wordx[word]\n",
        "  output = model_init.predict([word])\n",
        "  output_seq = output[0]\n",
        "  new_states = output[1:]\n",
        "  init = new_states\n",
        "  new_id = np.argmax(output_seq[0,-1,:])\n",
        "  new_word = idx[new_id]\n",
        "  word = np.array([[new_id]]) \n",
        "  stop = False\n",
        "  sentence = \"\"\n",
        "  sentence += new_word + \" \"\n",
        "  while not stop:\n",
        "      output = model_second.predict([word] + init)\n",
        "      output_seq = output[0]\n",
        "      new_states = output[1:]\n",
        "      new_id = np.argmax(output_seq[0,-1,:])\n",
        "      new_word = idx[new_id]\n",
        "      \n",
        "\n",
        "      if (new_word ==  \"<EOS>\" or len(sentence.split()) == MAXLEN):\n",
        "        stop = True\n",
        "      else: \n",
        "        sentence += new_word + \" \"\n",
        "      word = np.array([[new_id]]) \n",
        "      init = new_states\n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}